{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CrossValidation  on churn modelling.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMHg3NyXi0uo5HLBZ6q0M/7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Awoyawson/Artificial-Neutral-Network/blob/main/CrossValidation_on_churn_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L2jx7pDVf1P"
      },
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv('Churn_Modelling.csv')  \n",
        "X = dataset.iloc[:, 3: 13].values\n",
        "y = dataset.iloc[:, 13].values"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7AaM0aQVjTz"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder_X_1 = LabelEncoder() #instantiate an object of the class LabelEncoder\n",
        "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1]) #ordinal encoding for column 1\n",
        "\n",
        "labelencoder_X_2 = LabelEncoder()\n",
        "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2]) #ordinal encoding for column 2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYERIY2vTW5O"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import numpy as np\n",
        "ct = ColumnTransformer( #'encoder' is the name of the column transformer\n",
        "    [('encoder', OneHotEncoder(), [1])],    # The column numbers to be transformed (here is [1] but can be [0, 1, 3])\n",
        "    remainder='passthrough'                         # Leave the rest of the columns untouched\n",
        ")\n",
        "X = np.array(ct.fit_transform(X), dtype=np.float)\n",
        "\n",
        "X = X[:, 1:]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQqDsjgKXSx5"
      },
      "source": [
        "#Standardise the data (x_standardised = (x - x_mean)/std_dev)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "'''X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test) #note that we use the scale set from the training set to transform the test set'''\n",
        "X = sc.fit_transform(X)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wmGI_kLXSt4"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  #add input layer and first hidden layer\n",
        "  model.add(tf.keras.layers.Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "  #add 2nd hidden layer\n",
        "  model.add(tf.keras.layers.Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "  #output layer\n",
        "  model.add(tf.keras.layers.Dense(units=1, kernel_initializer='uniform', activation='sigmoid')) #Sigmoid for binary, Softmax for multiclass\n",
        "  \n",
        "  model.compile(optimizer = 'adam', loss ='binary_crossentropy', metrics = ['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bjcxypBXSqG",
        "outputId": "0a37e494-ee81-4586-b27a-666d810eb934"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "n_split = 4\n",
        "\n",
        "for train_index,test_index in KFold(n_split).split(X):\n",
        "  x_train, x_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  \n",
        "  model = create_model()\n",
        "  model.fit(x_train, y_train, epochs=20, verbose=0)\n",
        "  \n",
        "  print('Model evaluation ', model.evaluate(x_test,y_test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 0s 1ms/step - loss: 0.4080 - accuracy: 0.8272\n",
            "Model evaluation  [0.40799078345298767, 0.8271999955177307]\n",
            "79/79 [==============================] - 0s 1ms/step - loss: 0.4097 - accuracy: 0.8292\n",
            "Model evaluation  [0.4096606969833374, 0.829200029373169]\n",
            "79/79 [==============================] - 0s 958us/step - loss: 0.3974 - accuracy: 0.8424\n",
            "Model evaluation  [0.39744800329208374, 0.8424000144004822]\n",
            "79/79 [==============================] - 0s 973us/step - loss: 0.4121 - accuracy: 0.8372\n",
            "Model evaluation  [0.4121260344982147, 0.8371999859809875]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BfyIyc_XSlP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}